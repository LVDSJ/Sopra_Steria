{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a262d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install mediapipe opencv-python\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2ad7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1751282694.469808 1895165 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M3\n",
      "W0000 00:00:1751282694.476567 1917958 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1751282694.481574 1917960 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 129\u001b[0m\n\u001b[1;32m    126\u001b[0m             motion_buffers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRight\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m    128\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHand Sign Detection\u001b[39m\u001b[38;5;124m\"\u001b[39m, frame)\n\u001b[0;32m--> 129\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m27\u001b[39m:  \u001b[38;5;66;03m# ESC to quit\u001b[39;00m\n\u001b[1;32m    130\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    132\u001b[0m cap\u001b[38;5;241m.\u001b[39mrelease()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Motion tracking for waving - MOVED OUTSIDE THE LOOP\n",
    "motion_buffers = {\"Left\": deque(maxlen=20), \"Right\": deque(maxlen=20)}\n",
    "\n",
    "def count_fingers(hand_landmarks, handedness):\n",
    "    fingers = []\n",
    "    tip_ids = [4, 8, 12, 16, 20]\n",
    "\n",
    "    # Thumb (flip logic for right hand)\n",
    "    if handedness == \"Right\":\n",
    "        if hand_landmarks.landmark[tip_ids[0]].x < hand_landmarks.landmark[tip_ids[0] - 1].x:\n",
    "            fingers.append(1)\n",
    "        else:\n",
    "            fingers.append(0)\n",
    "    else:\n",
    "        if hand_landmarks.landmark[tip_ids[0]].x > hand_landmarks.landmark[tip_ids[0] - 1].x:\n",
    "            fingers.append(1)\n",
    "        else:\n",
    "            fingers.append(0)\n",
    "\n",
    "    # Other four fingers (same logic)\n",
    "    for id in range(1, 5):\n",
    "        if hand_landmarks.landmark[tip_ids[id]].y < hand_landmarks.landmark[tip_ids[id] - 2].y:\n",
    "            fingers.append(1)\n",
    "        else:\n",
    "            fingers.append(0)\n",
    "\n",
    "    return fingers\n",
    "\n",
    "def detect_hand_sign(fingers):\n",
    "    total_fingers = sum(fingers)\n",
    "    if total_fingers == 5:\n",
    "        return \"Open hand\"\n",
    "    elif fingers == [1, 0, 0, 0, 1]:\n",
    "        return \"Surf hand\"\n",
    "    elif fingers == [0, 1, 1, 0, 0]:\n",
    "        return \"Peace hand\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "def detect_wave(buffer, min_peaks=3, min_amplitude=0.05):\n",
    "    if len(buffer) < 15:  # Need enough data points\n",
    "        return False\n",
    "\n",
    "    x_positions = np.array(buffer)\n",
    "    \n",
    "    # Smooth the data to reduce noise\n",
    "    if len(x_positions) > 3:\n",
    "        smoothed = np.convolve(x_positions, np.ones(3)/3, mode='valid')\n",
    "    else:\n",
    "        smoothed = x_positions\n",
    "    \n",
    "    if len(smoothed) < 5:\n",
    "        return False\n",
    "    \n",
    "    # Calculate derivatives to find direction changes\n",
    "    diffs = np.diff(smoothed)\n",
    "    \n",
    "    # Find peaks and valleys (direction changes)\n",
    "    sign_changes = 0\n",
    "    for i in range(1, len(diffs)):\n",
    "        if (diffs[i-1] > 0 and diffs[i] < 0) or (diffs[i-1] < 0 and diffs[i] > 0):\n",
    "            sign_changes += 1\n",
    "    \n",
    "    # Check motion amplitude\n",
    "    motion_range = np.max(x_positions) - np.min(x_positions)\n",
    "    \n",
    "    # More lenient thresholds for better detection\n",
    "    return sign_changes >= min_peaks and motion_range >= min_amplitude\n",
    "\n",
    "# Camera loop\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.5) as hands:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Flip for natural view\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(image_rgb)\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            hand_signs = []\n",
    "\n",
    "            for idx, hand_landmarks in enumerate(results.multi_hand_landmarks):\n",
    "                handedness = results.multi_handedness[idx].classification[0].label\n",
    "\n",
    "                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                fingers = count_fingers(hand_landmarks, handedness)\n",
    "                sign = detect_hand_sign(fingers)\n",
    "\n",
    "                # Track wrist x-position for waving motion\n",
    "                wrist_x = hand_landmarks.landmark[0].x\n",
    "                motion_buffers[handedness].append(wrist_x)\n",
    "\n",
    "                # Replace Open Hand with Waving if waving is detected\n",
    "                if sign == \"Open hand\" and detect_wave(motion_buffers[handedness]):\n",
    "                    sign = \"Waving\"\n",
    "\n",
    "                # Append full label\n",
    "                hand_label = f\"{handedness} {sign}\"\n",
    "                if hand_label not in hand_signs:\n",
    "                    hand_signs.append(hand_label)\n",
    "\n",
    "            # Combine if multiple hands\n",
    "            final_sign = \" | \".join(hand_signs) if hand_signs else \"\"\n",
    "\n",
    "            # Show on screen\n",
    "            cv2.putText(frame, final_sign, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 255, 0), 3)\n",
    "        else:\n",
    "            # Clear motion buffers when no hands are detected\n",
    "            motion_buffers[\"Left\"].clear()\n",
    "            motion_buffers[\"Right\"].clear()\n",
    "\n",
    "        cv2.imshow(\"Hand Sign Detection\", frame)\n",
    "        if cv2.waitKey(10) & 0xFF == 27:  # ESC to quit\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sopra_steria",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
